import os
import yaml
import csv
import operator
import elasticsearch
import requests
import json
import pymysql

from collections import defaultdict
from datetime import date, datetime, timedelta
from sqlalchemy import Column, Integer, String
from sqlalchemy import create_engine
from sqlalchemy.orm import Session
from sqlalchemy import or_
from sqlalchemy import and_
from sqlalchemy import ForeignKey
from sqlalchemy.orm import relationship
from sqlalchemy.orm import load_only
from sqlalchemy.types import VARBINARY
from sqlalchemy import func
from sqlalchemy.orm import subqueryload
from sqlalchemy.orm import joinedload
from sqlalchemy.ext.automap import automap_base
from sqlalchemy.orm import sessionmaker
from sqlalchemy import desc
from sqlalchemy import asc


from api.clerk import Clerk

class Controller(object):
    """
    This class sets and manages the entire communication protocol with
    the declassification engine databases through the SQLAlchemy-ORM
    package.

    An object of this class invokes a query across multiple collections
    and sorts the combined results in memory.
    """
    ROOT = os.getcwd()
    CONFIG = os.path.join(ROOT, 'config')

    api_config = yaml.load(open(os.path.join(CONFIG, 'api_config.yml')))
    databases_names = api_config['databases']
    collection_names = api_config['collections']
    entity_names = api_config['entities']
    supported_versions = api_config['supported_versions']

    data_path = os.path.join(ROOT, 'data/topics')
    topic_token_path = os.path.join(data_path, 'tokens')
    topic_doc_path = os.path.join(data_path, 'docs')

    conn_config = yaml.load(open(os.path.join(CONFIG, 'conn_config.yml')))

    HTTP_STATUS_SUCCESS = 200
    HTTP_STATUS_BAD_REQUEST = 404
    PAGE_SIZE_DEFAULT = int(api_config['parameters']['page_size'])

    def __init__(self, connection_type):
        '''
        Building connections to all databases specified in the api configuration file api_config.yml
        This function creates an engine object for each database, and automatically maps the database tables
        using SQLAlchemy's reflection Base reflection property.

        A Session factory containing the engines and table properties is prepared once and made available
        for all future session requests.
        '''

        credentials = Controller.conn_config[connection_type]
        username = os.getenv('DECLASS_API_USER') or credentials['user']
        password = os.getenv('DECLASS_API_PW') or credentials['password']
        host = 'history-lab.org' or credentials['host']

        self.Tables = defaultdict(dict)
        self.Entities = defaultdict(dict)
        self.Topics = defaultdict(dict)
        self.clerk = Clerk(self)
        self.supported_versions = Controller.supported_versions
        self.es = elasticsearch.Elasticsearch()

        Engines = {}
        Bases = {}
        Binds = {}

        # Create all database connections
        for database in Controller.databases_names:
            # Create engines to connect to databases
            Engines[database] = create_engine('mysql+pymysql://' + str(username) + ':' + str(password) + '@' + str(host) + '/' + str(database) + '?charset=utf8&use_unicode=1', pool_recycle=3600)
            # Reflect the tables
            Bases[database] = automap_base()
            Bases[database].prepare(Engines[database], reflect=True)
            self.Entities[database] = []

            # Creating a table to store all the table names of the databases
            for table in Bases[database].classes:
                self.Tables[database][table.__name__] = table

            # Explicitly store the list of available entities for a specific database
            for entity in Controller.entity_names:
                if entity in self.Tables[database].keys():
                    self.Entities[database].append(entity)

            Binds[ Bases[database] ] = Engines[database]

        # Create Factory class for the sessions
        self.Session = sessionmaker(binds=Binds)

        self.__init_topics()


    def __init_topics(self):
        """
        This function loads the static token and topic data files
        that have been pre-generated by the external topics script.
        """
        # Load all data for topic routes
        session = self.Session()

        collections = [
            'frus',
            'ddrs',
            'kissinger',
            'cpdoc'
        ]

        for collection in collections:
            database = self.collection_names[collection]
            table_names = self.Tables[database].keys()

            if 'topic_doc' in table_names:
                topic_doc = self.Tables[database]['topic_doc']
                # the set of possible doc_ids will be loaded here.
                result = session.query(topic_doc.doc_id).distinct(topic_doc.doc_id).all()

                self.Topics[database]['valid_doc_ids'] = {doc_id for (doc_id,) in result}

                # possible topic_ids will be loaded here.
                result = session.query(topic_doc.topic_id).distinct(topic_doc.topic_id)

                self.Topics[database]['valid_topic_ids'] = {topic_id for (topic_id,) in result}

                if collection == "cpdoc":
                    topics = self.Tables[database]['topics']
                    result = session.query(topics.id).filter(topics.name.isnot(None))

                    self.Topics[database]['valid_topic_ids'] = {id for (id,) in result}
                # Load in all the topic
                top_topic_tokens = {}
                for topic_id in self.Topics[database]['valid_topic_ids']:
                    topic_tokens = []
                    filename = '{}.csv'.format(topic_id)
                    current_path = os.path.join(Controller.topic_token_path, "{}".format(collection), filename)
                    with open(current_path, 'rU') as infile:
                        reader = csv.reader(infile)
                        keys = next(reader)
                        for row in reader:
                            topic_tokens.append(dict(zip(keys, row)))
                    top_topic_tokens[topic_id] = topic_tokens

                self.Topics[database]['top_topic_tokens'] = top_topic_tokens

                # Load in all the doc data.
                top_topic_docs = {}
                for topic_id in self.Topics[database]['valid_topic_ids']:
                    topic_docs = []
                    top_topic_docs[topic_id] = topic_docs
                    filename = '{}.csv'.format(topic_id)
                    current_path = os.path.join(Controller.topic_doc_path, "{}".format(collection), filename)
                    with open(current_path) as infile:
                        reader = csv.reader(infile)
                        keys = next(reader)
                        for row in reader:
                            topic_docs.append(dict(zip(keys, row)))
                    top_topic_docs[topic_id] = topic_docs
                self.Topics[database]['top_topic_docs'] = top_topic_docs

        session.close()


    def populate_docs_entities(self, session, db_results_flat, database, filters):
        """
        This function takes a list of document ids and queries the databases
        to collect their entities (persons, topics, countries) lists.

        @type  session: object
        @param session: A session factory object configured to access all databases.
        @type  db_results_flat: dictionary
        @param db_results_flat: A json dictionary containing the document results to
            return to the user.
        @type  database: string
        @param database: The name of the collection to query.
        @type  filters: dictionary
        @param filters: A list of filters to constrain a query.

        @rtype:   None
        @return:  Modifies the db_results_flat object and populates entities.
        """

        doc_ids = []
        doc_ids_entities = {}
        for row in db_results_flat:
            doc_ids.append(row['id'])
            doc_ids_entities[row['id']] = {'countries':None, 'persons':None}

        if doc_ids:
            # Get countries related to doc_id
            if 'countries' in table_names and 'country_doc' in table_names and 'countries' in filters['fields']:
                countries = self.Tables[database]['countries']
                country_doc = self.Tables[database]['country_doc']

                q = session.query(country_doc.doc_id, func.group_concat(countries.name))\
                            .filter(country_doc.doc_id.in_(doc_ids))\
                            .join(countries)\
                            .group_by(country_doc.doc_id)

                country_list = q.all()

                for (doc_id, countries) in country_list:
                    doc_ids_entities[doc_id]["countries"] = ", ".join([c.strip() for c in countries.split(',')])

            # Get persons related to doc_id
            if 'persons' in table_names and 'person_doc' in table_names and 'persons' in filters['fields']:
                persons = self.Tables[database]['persons']
                person_doc = self.Tables[database]['person_doc']
                #q = session.query(persons.name).join(person_doc).filter(person_doc.doc_id == row.doc_id)
                q = session.query(person_doc.doc_id, func.group_concat(persons.name))\
                            .join(persons)\
                            .filter(person_doc.doc_id.in_(doc_ids))\
                            .group_by(person_doc.doc_id)

                persons_list = q.all()

                for (doc_id, persons) in persons_list:
                    doc_ids_entities[doc_id]["persons"] = ", ".join([p.strip() for p in persons.split(',')])

            # Get topics related to doc_id
            if 'topics' in table_names and 'topic_doc' in table_names and 'topics' in filters['fields']:
                topics = self.Tables[database]['topics']
                topic_doc = self.Tables[database]['topic_doc']
                q = session.query(topic_doc.doc_id, func.group_concat(topics.name))\
                            .join(topics)\
                            .filter(topic_doc.doc_id.in_(doc_ids))\
                            .group_by(topic_doc.doc_id)

                topics_list = q.all()

                for (doc_id, topics) in topics_list:
                    if topics:
                        doc_ids_entities[doc_id]["topics"] = ", ".join([t.strip() for t in topics.split(',')])


            for row in db_results_flat:
                if 'countries' in filters['fields']:
                    row["countries"] = None
                    if "countries" in doc_ids_entities[row['id']]:
                        row['countries'] = doc_ids_entities[row['id']]['countries']
                if 'persons' in filters['fields']:
                    row['persons'] = None
                    if "persons" in doc_ids_entities[row['id']]:
                        row['persons'] = doc_ids_entities[row['id']]['persons']
                if 'topics' in filters['fields']:
                    row["topics"] = None
                    if "topics" in doc_ids_entities[row['id']]:
                        row['topics'] = doc_ids_entities[row['id']]['topics']


    def find_docs_by_ids(self, doc_ids, filters):
        """
        This function returns the document information of a list of
        doc_ids.

        @type  doc_ids: list
        @param doc_ids: A list of document ids to query the databases for.
        @type  filters: dictionary
        @param filters: A list of filters to constrain a query.

        @rtype:   json
        @return:  Array of documents info.
        """
        session = self.Session()
        result_list = []

        docdb = self.Tables['declassification_api']['docdb']
        # List the databases that we need to search documents in
        db_locations = session.query(docdb.db_name).filter(docdb.doc_id.in_(doc_ids)).group_by(docdb.db_name).all()

        for database in db_locations:
            docs = self.Tables[database.db_name]['docs']
            q = session.query(docs).filter(docs.id.in_(doc_ids))
            q = self.__apply_query_filters(session, q, docs, filters, collection=None)

            db_results_objects = q.all()    # returns all documents
            db_results_flat = self.__package_db_results(db_results_objects, filters)
            self.populate_docs_entities(session, db_results_flat, database.db_name, filters)
            result_list.extend(db_results_flat)


        session.close()
        response = self.clerk.process(result_list, Controller.HTTP_STATUS_SUCCESS, self.clerk.JSON.encode)
        response.mimetype = 'application/json'
        response.headers['Content-Type'] = 'application/json'
        return response


    def find_docs_by_persons(self, p_ids, p_logic, filters):
        """
        This function returns the document information given a list
        of person ids.

        @type  p_ids: list
        @param p_ids: A list of person ids to query the databases for.
        @type  p_logic: string
        @param p_logic: AND / OR operator
        @type  filters: dictionary
        @param filters: A list of filters to constrain a query.

        @rtype:   json
        @return:  Array of documents info.
        """
        session = self.Session()
        result_list = []
        total_count = 0

        for collection in filters['collections']:
            database = self.collection_names[collection]

            table_names = self.Tables[database].keys()
            if 'persons' in table_names and 'person_doc' in table_names and 'docs' in table_names:
                persons = self.Tables[database]['persons']
                person_doc = self.Tables[database]['person_doc']
                docs = self.Tables[database]['docs']

                # We want to get the document ids associated with the input person_ids
                person_query = session.query(person_doc.doc_id)\
                                      .filter(person_doc.person_id.in_(p_ids))

                #q = session.query(docs).join(person_doc).join(persons).filter(persons.id.in_(p_ids))
                if p_logic == 'AND':
                    person_query = person_query.group_by(person_doc.doc_id)\
                                                 .having(func.count('*') == len(set(p_ids)))

                q = session.query(docs).filter(docs.id.in_(person_query))

                q = self.__apply_query_filters(session, q, docs, filters, collection)
                db_results_objects = q.all()    # returns all documents

                if len(db_results_objects) > 0:
                    count = int(db_results_objects[0][0])
                    total_count = total_count + count

                db_results_flat = self.__package_db_results(db_results_objects, filters)

                self.populate_docs_entities(session, db_results_flat, database, filters)

                for row in db_results_flat:
                    date_val = row['date']
                    if not date_val:
                        date_val = datetime(1200, 1, 1, 0, 0)
                    if isinstance(date_val, date):
                        # convert to datetime object if it's just date
                        date_val = datetime.combine(date_val, datetime.min.time())
                    result_list.append((row, collection, date_val))

        (results_combined, collection_next_index, has_next) = self.__merge_collections_results(result_list, filters['page_size'], filters['page_start_index'].copy())

        # build link
        collapsed_start_index = ":".join([":".join([key, str(value)]) for key, value in filters['page_start_index'].items()])
        collapsed_next_index = ":".join([":".join([key, str(value)]) for key, value in collection_next_index.items()])
        next_page = self.clerk.build_link(filters['page_url'], collapsed_start_index, collapsed_next_index, has_next)

        response = self.clerk.process(results_combined, Controller.HTTP_STATUS_SUCCESS, self.clerk.JSON.encode,
            page=collapsed_start_index, page_size=Controller.PAGE_SIZE_DEFAULT, next_page=next_page,count=total_count)
        response.mimetype = 'application/json'
        response.headers['Content-Type'] = 'application/json'
        session.close()
        return response


    def find_docs_by_country(self, c_ids, c_logic, filters):
        """
        This function returns the document information given a list
        of country ids.

        @type  c_ids: list
        @param c_ids: A list of country ids to query the databases for.
        @type  c_logic: string
        @param c_logic: AND / OR operator
        @type  filters: dictionary
        @param filters: A list of filters to constrain a query.

        @rtype:   json
        @return:  Array of documents info.
        """
        session = self.Session()
        result_list = []
        total_count = 0

        for collection in filters['collections']:
            database = self.collection_names[collection]

            table_names = self.Tables[database].keys()
            if 'countries' in table_names and 'country_doc' in table_names and 'docs' in table_names:
                countries = self.Tables[database]['countries']
                country_doc = self.Tables[database]['country_doc']
                docs = self.Tables[database]['docs']

                # We want to get the document ids associated with the input c_ids
                country_query = session.query(country_doc.doc_id)\
                                       .filter(country_doc.country_id.in_(c_ids))

                if c_logic == 'AND':
                    country_query = country_query.group_by(country_doc.doc_id)\
                                                 .having(func.count('*') == len(set(c_ids)))

                q = session.query(docs).filter(docs.id.in_(country_query))

                q = self.__apply_query_filters(session, q, docs, filters, collection)
                db_results_objects = q.all()    # returns all documents

                if len(db_results_objects) > 0:
                    count = int(db_results_objects[0][0])
                    total_count = total_count + count

                db_results_flat = self.__package_db_results(db_results_objects, filters)

                self.populate_docs_entities(session, db_results_flat, database, filters)

                for row in db_results_flat:
                    date_val = row['date']
                    if not date_val:
                        date_val = datetime(1200, 1, 1, 0, 0)
                    if isinstance(date_val, date):
                        # convert to datetime object if it's just date
                        date_val = datetime.combine(date_val, datetime.min.time())
                    result_list.append((row, collection, date_val))

        (results_combined, collection_next_index, has_next) = self.__merge_collections_results(result_list, filters['page_size'], filters['page_start_index'].copy())

        # build link
        collapsed_start_index = ":".join([":".join([key, str(value)]) for key, value in filters['page_start_index'].items()])
        collapsed_next_index = ":".join([":".join([key, str(value)]) for key, value in collection_next_index.items()])
        next_page = self.clerk.build_link(filters['page_url'], collapsed_start_index, collapsed_next_index, has_next)

        response = self.clerk.process(results_combined, Controller.HTTP_STATUS_SUCCESS, self.clerk.JSON.encode,
            page=collapsed_start_index, page_size=Controller.PAGE_SIZE_DEFAULT, next_page=next_page,count=total_count)
        response.mimetype = 'application/json'
        response.headers['Content-Type'] = 'application/json'
        session.close()
        return response


    def find_docs_by_topic(self, t_ids, t_logic, filters):
        """
        This function returns the document information given a list
        of topic ids.

        @type  t_ids: list
        @param t_ids: A list of topic ids to query the databases for.
        @type  t_logic: string
        @param t_logic: AND / OR operator
        @type  filters: dictionary
        @param filters: A list of filters to constrain a query.

        @rtype:   json
        @return:  Array of documents info.
        """
        session = self.Session()
        result_list = []
        total_count = 0

        for collection in filters['collections']:
            database = self.collection_names[collection]

            table_names = self.Tables[database].keys()
            if 'topics' in table_names and 'topic_doc' in table_names and 'docs' in table_names:
                topics = self.Tables[database]['topics']
                topic_doc = self.Tables[database]['topic_doc']
                docs = self.Tables[database]['docs']

                # We want to get the document ids associated with the input c_ids
                topic_query = session.query(topic_doc.doc_id)\
                                       .filter(topic_doc.topic_id.in_(t_ids))

                if t_logic == 'AND':
                    topic_query = topic_query.group_by(topic_doc.doc_id)\
                                                 .having(func.count('*') == len(set(t_ids)))

                q = session.query(docs).filter(docs.id.in_(topic_query))

                q = self.__apply_query_filters(session, q, docs, filters, collection)
                db_results_objects = q.all()    # returns all documents

                if len(db_results_objects) > 0:
                    count = int(db_results_objects[0][0])
                    total_count = total_count + count

                db_results_flat = self.__package_db_results(db_results_objects, filters)

                self.populate_docs_entities(session, db_results_flat, database, filters)

                for row in db_results_flat:
                    date_val = row['date']
                    if not date_val:
                        date_val = datetime(1200, 1, 1, 0, 0)
                    if isinstance(date_val, date):
                        # convert to datetime object if it's just date
                        date_val = datetime.combine(date_val, datetime.min.time())
                    result_list.append((row, collection, date_val))

        (results_combined, collection_next_index, has_next) = self.__merge_collections_results(result_list, filters['page_size'], filters['page_start_index'].copy())

        # build link
        collapsed_start_index = ":".join([":".join([key, str(value)]) for key, value in filters['page_start_index'].items()])
        collapsed_next_index = ":".join([":".join([key, str(value)]) for key, value in collection_next_index.items()])
        next_page = self.clerk.build_link(filters['page_url'], collapsed_start_index, collapsed_next_index, has_next)

        response = self.clerk.process(results_combined, Controller.HTTP_STATUS_SUCCESS, self.clerk.JSON.encode,
            page=collapsed_start_index, page_size=Controller.PAGE_SIZE_DEFAULT, next_page=next_page,count=total_count)
        response.mimetype = 'application/json'
        response.headers['Content-Type'] = 'application/json'
        session.close()
        return response


    def find_docs_by_classification(self, t_ids, t_logic, filters):
        """
        This function returns the document information given a list
        of classification ids.

        @type  t_ids: list
        @param t_ids: A list of classification ids to query the databases for.
        @type  t_logic: string
        @param t_logic: AND / OR operator
        @type  filters: dictionary
        @param filters: A list of filters to constrain a query.

        @rtype:   json
        @return:  Array of documents info.
        """
        session = self.Session()
        result_list = []
        total_count = 0

        for collection in filters['collections']:
            database = self.collection_names[collection]

            table_names = self.Tables[database].keys()
            if 'classifications' in table_names and 'classification_doc' in table_names and 'docs' in table_names:
                classifications = self.Tables[database]['classifications']
                classification_doc = self.Tables[database]['classification_doc']
                docs = self.Tables[database]['docs']

                # We want to get the document ids associated with the input classification_ids
                classification_query = session.query(classification_doc.doc_id)\
                                       .filter(classification_doc.classification_id.in_(t_ids))

                if t_logic == 'AND':
                    classification_query = classification_query.group_by(classification_doc.doc_id)\
                                                 .having(func.count('*') == len(set(t_ids)))

                q = session.query(docs).filter(docs.id.in_(classification_query))

                q = self.__apply_query_filters(session, q, docs, filters, collection)
                db_results_objects = q.all()    # returns all documents

                if len(db_results_objects) > 0:
                    count = int(db_results_objects[0][0])
                    total_count = total_count + count

                db_results_flat = self.__package_db_results(db_results_objects, filters)

                self.populate_docs_entities(session, db_results_flat, database, filters)

                for row in db_results_flat:
                    date_val = row['date']
                    if not date_val:
                        date_val = datetime(1200, 1, 1, 0, 0)
                    if isinstance(date_val, date):
                        # convert to datetime object if it's just date
                        date_val = datetime.combine(date_val, datetime.min.time())
                    result_list.append((row, collection, date_val))

        (results_combined, collection_next_index, has_next) = self.__merge_collections_results(result_list, filters['page_size'], filters['page_start_index'].copy())

        # build link
        collapsed_start_index = ":".join([":".join([key, str(value)]) for key, value in filters['page_start_index'].items()])
        collapsed_next_index = ":".join([":".join([key, str(value)]) for key, value in collection_next_index.items()])
        next_page = self.clerk.build_link(filters['page_url'], collapsed_start_index, collapsed_next_index, has_next)

        response = self.clerk.process(results_combined, Controller.HTTP_STATUS_SUCCESS, self.clerk.JSON.encode,
            page=collapsed_start_index, page_size=Controller.PAGE_SIZE_DEFAULT, next_page=next_page,count=total_count)
        response.mimetype = 'application/json'
        response.headers['Content-Type'] = 'application/json'
        session.close()
        return response

    def find_docs_by_person_classification(self, p_ids, p_logic, c_ids, c_logic, filters):
        """
        This function returns the document information given a list
        of person and classification ids.

        @type  p_ids: list
        @param p_ids: A list of person ids to query the database for.
        @type  p_logic: string
        @param p_logic: AND / OR operator
        @type  c_ids: list
        @param c_ids: A list of classification ids to query the databases for.
        @type  c_logic: string
        @param c_logic: AND / OR operator
        @type  filters: dictionary
        @param filters: A list of filters to constrain a query.

        @rtype:   json
        @return:  Array of documents info.
        """
        session = self.Session()
        result_list = []
        total_count = 0

        for collection in filters['collections']:
            database = self.collection_names[collection]

            table_names = self.Tables[database].keys()
            if set(['persons', 'person_doc', 'classifications', 'classification_doc', 'docs']) <= set(table_names):
            #if 'persons' in table_names and 'person_doc' in table_names and 'classifications' in table_names and 'classification_doc' in table_names and 'docs' in table_names:
                persons = self.Tables[database]['persons']
                person_doc = self.Tables[database]['person_doc']
                classifications = self.Tables[database]['classifications']
                classification_doc = self.Tables[database]['classification_doc']
                docs = self.Tables[database]['docs']

                person_query = session.query(person_doc.doc_id)\
                                      .filter(person_doc.person_id.in_(p_ids))

                classification_query = session.query(classification_doc.doc_id)\
                                       .filter(classification_doc.classification_id.in_(c_ids))

                if p_logic == 'AND':
                    person_query = person_query.group_by(person_doc.doc_id)\
                                                 .having(func.count('*') == len(set(p_ids)))

                if c_logic == 'AND':
                    classification_query = classification_query.group_by(classification_doc.doc_id)\
                                                 .having(func.count('*') == len(set(c_ids)))

                q = session.query(docs).filter(and_(docs.id.in_(person_query), docs.id.in_(classification_query)))

                q = self.__apply_query_filters(session, q, docs, filters, collection)
                db_results_objects = q.all()    # executes query and returns all documents

                if len(db_results_objects) > 0:
                    count = int(db_results_objects[0][0])
                    total_count = total_count + count

                db_results_flat = self.__package_db_results(db_results_objects, filters)

                self.populate_docs_entities(session, db_results_flat, database, filters)

                for row in db_results_flat:
                    date_val = row['date']
                    if not date_val:
                        date_val = datetime(1200, 1, 1, 0, 0)
                    if isinstance(date_val, date):
                        # convert to datetime object if it's just date
                        date_val = datetime.combine(date_val, datetime.min.time())
                    result_list.append((row, collection, date_val))

        (results_combined, collection_next_index, has_next) = self.__merge_collections_results(result_list, filters['page_size'], filters['page_start_index'].copy())

        # build link
        collapsed_start_index = ":".join([":".join([key, str(value)]) for key, value in filters['page_start_index'].items()])
        collapsed_next_index = ":".join([":".join([key, str(value)]) for key, value in collection_next_index.items()])
        next_page = self.clerk.build_link(filters['page_url'], collapsed_start_index, collapsed_next_index, has_next)

        response = self.clerk.process(results_combined, Controller.HTTP_STATUS_SUCCESS, self.clerk.JSON.encode,
            page=collapsed_start_index, page_size=Controller.PAGE_SIZE_DEFAULT, next_page=next_page,count=total_count)
        response.mimetype = 'application/json'
        response.headers['Content-Type'] = 'application/json'
        session.close()
        return response


    def find_docs_by_classification_country(self, p_ids, p_logic, c_ids, c_logic, filters):
        """
        This function returns the document information given a list
        of classification and country ids.

        @type  p_ids: list
        @param p_ids: A list of classification ids to query the database for.
        @type  p_logic: string
        @param p_logic: AND / OR operator
        @type  c_ids: list
        @param c_ids: A list of country ids to query the databases for.
        @type  c_logic: string
        @param c_logic: AND / OR operator
        @type  filters: dictionary
        @param filters: A list of filters to constrain a query.

        @rtype:   json
        @return:  Array of documents info.
        """
        session = self.Session()
        result_list = []
        total_count = 0

        for collection in filters['collections']:
            database = self.collection_names[collection]

            table_names = self.Tables[database].keys()
            if set(['classifications', 'classification_doc', 'countries', 'country_doc', 'docs']) <= set(table_names):
            #if 'classifications' in table_names and 'classification_doc' in table_names and 'countries' in table_names and 'country_doc' in table_names and 'docs' in table_names:
                classifications = self.Tables[database]['classifications']
                classification_doc = self.Tables[database]['classification_doc']
                countries = self.Tables[database]['countries']
                country_doc = self.Tables[database]['country_doc']
                docs = self.Tables[database]['docs']

                classification_query = session.query(classification_doc.doc_id)\
                                      .filter(classification_doc.classification_id.in_(p_ids))

                country_query = session.query(country_doc.doc_id)\
                                       .filter(country_doc.country_id.in_(c_ids))

                if p_logic == 'AND':
                    classification_query = classification_query.group_by(classification_doc.doc_id)\
                                                 .having(func.count('*') == len(set(p_ids)))

                if c_logic == 'AND':
                    country_query = country_query.group_by(country_doc.doc_id)\
                                                 .having(func.count('*') == len(set(c_ids)))

                q = session.query(docs).filter(and_(docs.id.in_(classification_query), docs.id.in_(country_query)))

                q = self.__apply_query_filters(session, q, docs, filters, collection)
                db_results_objects = q.all()    # executes query and returns all documents

                if len(db_results_objects) > 0:
                    count = int(db_results_objects[0][0])
                    total_count = total_count + count

                db_results_flat = self.__package_db_results(db_results_objects, filters)

                self.populate_docs_entities(session, db_results_flat, database, filters)

                for row in db_results_flat:
                    date_val = row['date']
                    if not date_val:
                        date_val = datetime(1200, 1, 1, 0, 0)
                    if isinstance(date_val, date):
                        # convert to datetime object if it's just date
                        date_val = datetime.combine(date_val, datetime.min.time())
                    result_list.append((row, collection, date_val))

        (results_combined, collection_next_index, has_next) = self.__merge_collections_results(result_list, filters['page_size'], filters['page_start_index'].copy())

        # build link
        collapsed_start_index = ":".join([":".join([key, str(value)]) for key, value in filters['page_start_index'].items()])
        collapsed_next_index = ":".join([":".join([key, str(value)]) for key, value in collection_next_index.items()])
        next_page = self.clerk.build_link(filters['page_url'], collapsed_start_index, collapsed_next_index, has_next)

        response = self.clerk.process(results_combined, Controller.HTTP_STATUS_SUCCESS, self.clerk.JSON.encode,
            page=collapsed_start_index, page_size=Controller.PAGE_SIZE_DEFAULT, next_page=next_page,count=total_count)
        response.mimetype = 'application/json'
        response.headers['Content-Type'] = 'application/json'
        session.close()
        return response

    def find_docs_by_classification_topic(self, c_ids, c_logic, t_ids, t_logic, filters):
        """
        This function returns the document information given a list
        of classification and topic ids.

        @type  c_ids: list
        @param c_ids: A list of classification ids to query the database for.
        @type  c_logic: string
        @param c_logic: AND / OR operator
        @type  t_ids: list
        @param t_ids: A list of topic ids to query the databases for.
        @type  t_logic: string
        @param t_logic: AND / OR operator
        @type  filters: dictionary
        @param filters: A list of filters to constrain a query.

        @rtype:   json
        @return:  Array of documents info.
        """
        session = self.Session()
        result_list = []
        total_count = 0

        for collection in filters['collections']:
            database = self.collection_names[collection]

            table_names = self.Tables[database].keys()
            if set(['topics', 'topic_doc', 'classifications', 'classification_doc', 'docs']) <= set(table_names):
            #if 'topics' in table_names and 'topic_doc' in table_names and 'classifications' in table_names and 'classification_doc' in table_names and 'docs' in table_names:
                topics = self.Tables[database]['topics']
                topic_doc = self.Tables[database]['topic_doc']
                classifications = self.Tables[database]['classifications']
                classification_doc = self.Tables[database]['classification_doc']
                docs = self.Tables[database]['docs']

                topic_query = session.query(topic_doc.doc_id)\
                                     .filter(topic_doc.topic_id.in_(t_ids))

                classification_query = session.query(classification_doc.doc_id)\
                                       .filter(classification_doc.classification_id.in_(c_ids))

                if t_logic == 'AND':
                    topic_query = topic_query.group_by(topic_doc.doc_id)\
                                               .having(func.count('*') == len(set(t_ids)))

                if c_logic == 'AND':
                    classification_query = classification_query.group_by(classification_doc.doc_id)\
                                                 .having(func.count('*') == len(set(c_ids)))

                q = session.query(docs).filter(and_(docs.id.in_(topic_query), docs.id.in_(classification_query)))

                q = self.__apply_query_filters(session, q, docs, filters, collection)
                db_results_objects = q.all()    # executes query and returns all documents

                if len(db_results_objects) > 0:
                    count = int(db_results_objects[0][0])
                    total_count = total_count + count

                db_results_flat = self.__package_db_results(db_results_objects, filters)

                self.populate_docs_entities(session, db_results_flat, database, filters)

                for row in db_results_flat:
                    date_val = row['date']
                    if not date_val:
                        date_val = datetime(1200, 1, 1, 0, 0)
                    if isinstance(date_val, date):
                        # convert to datetime object if it's just date
                        date_val = datetime.combine(date_val, datetime.min.time())
                    result_list.append((row, collection, date_val))

        (results_combined, collection_next_index, has_next) = self.__merge_collections_results(result_list, filters['page_size'], filters['page_start_index'].copy())

        # build link
        collapsed_start_index = ":".join([":".join([key, str(value)]) for key, value in filters['page_start_index'].items()])
        collapsed_next_index = ":".join([":".join([key, str(value)]) for key, value in collection_next_index.items()])
        next_page = self.clerk.build_link(filters['page_url'], collapsed_start_index, collapsed_next_index, has_next)

        response = self.clerk.process(results_combined, Controller.HTTP_STATUS_SUCCESS, self.clerk.JSON.encode,
            page=collapsed_start_index, page_size=Controller.PAGE_SIZE_DEFAULT, next_page=next_page,count=total_count)
        response.mimetype = 'application/json'
        response.headers['Content-Type'] = 'application/json'
        session.close()
        return response

    def find_docs_by_person_country(self, p_ids, p_logic, c_ids, c_logic, filters):
        """
        This function returns the document information given a list
        of person and country ids.

        @type  p_ids: list
        @param p_ids: A list of person ids to query the database for.
        @type  p_logic: string
        @param p_logic: AND / OR operator
        @type  c_ids: list
        @param c_ids: A list of country ids to query the databases for.
        @type  c_logic: string
        @param c_logic: AND / OR operator
        @type  filters: dictionary
        @param filters: A list of filters to constrain a query.

        @rtype:   json
        @return:  Array of documents info.
        """
        session = self.Session()
        result_list = []
        total_count = 0

        for collection in filters['collections']:
            database = self.collection_names[collection]

            table_names = self.Tables[database].keys()
            if set(['persons', 'person_doc', 'countries', 'country_doc', 'docs']) <= set(table_names):
            #if 'persons' in table_names and 'person_doc' in table_names and 'countries' in table_names and 'country_doc' in table_names and 'docs' in table_names:
                persons = self.Tables[database]['persons']
                person_doc = self.Tables[database]['person_doc']
                countries = self.Tables[database]['countries']
                country_doc = self.Tables[database]['country_doc']
                docs = self.Tables[database]['docs']

                person_query = session.query(person_doc.doc_id)\
                                      .filter(person_doc.person_id.in_(p_ids))

                country_query = session.query(country_doc.doc_id)\
                                       .filter(country_doc.country_id.in_(c_ids))

                if p_logic == 'AND':
                    person_query = person_query.group_by(person_doc.doc_id)\
                                                 .having(func.count('*') == len(set(p_ids)))

                if c_logic == 'AND':
                    country_query = country_query.group_by(country_doc.doc_id)\
                                                 .having(func.count('*') == len(set(c_ids)))

                q = session.query(docs).filter(and_(docs.id.in_(person_query), docs.id.in_(country_query)))

                q = self.__apply_query_filters(session, q, docs, filters, collection)
                db_results_objects = q.all()    # executes query and returns all documents

                if len(db_results_objects) > 0:
                    count = int(db_results_objects[0][0])
                    total_count = total_count + count

                db_results_flat = self.__package_db_results(db_results_objects, filters)

                self.populate_docs_entities(session, db_results_flat, database, filters)

                for row in db_results_flat:
                    date_val = row['date']
                    if not date_val:
                        date_val = datetime(1200, 1, 1, 0, 0)
                    if isinstance(date_val, date):
                        # convert to datetime object if it's just date
                        date_val = datetime.combine(date_val, datetime.min.time())
                    result_list.append((row, collection, date_val))

        (results_combined, collection_next_index, has_next) = self.__merge_collections_results(result_list, filters['page_size'], filters['page_start_index'].copy())

        # build link
        collapsed_start_index = ":".join([":".join([key, str(value)]) for key, value in filters['page_start_index'].items()])
        collapsed_next_index = ":".join([":".join([key, str(value)]) for key, value in collection_next_index.items()])
        next_page = self.clerk.build_link(filters['page_url'], collapsed_start_index, collapsed_next_index, has_next)

        response = self.clerk.process(results_combined, Controller.HTTP_STATUS_SUCCESS, self.clerk.JSON.encode,
            page=collapsed_start_index, page_size=Controller.PAGE_SIZE_DEFAULT, next_page=next_page,count=total_count)
        response.mimetype = 'application/json'
        response.headers['Content-Type'] = 'application/json'
        session.close()
        return response


    def find_docs_by_person_topic(self, p_ids, p_logic, t_ids, t_logic, filters):
        """
        This function returns the document information given a list
        of person and topic ids.

        @type  p_ids: list
        @param p_ids: A list of person ids to query the database for.
        @type  p_logic: string
        @param p_logic: AND / OR operator
        @type  t_ids: list
        @param t_ids: A list of topic ids to query the databases for.
        @type  t_logic: string
        @param t_logic: AND / OR operator
        @type  filters: dictionary
        @param filters: A list of filters to constrain a query.

        @rtype:   json
        @return:  Array of documents info.
        """
        session = self.Session()
        result_list = []
        total_count = 0

        for collection in filters['collections']:
            database = self.collection_names[collection]

            table_names = self.Tables[database].keys()

            if set(['persons', 'person_doc', 'topics', 'topic_doc', 'docs']) <= set(table_names):
                persons = self.Tables[database]['persons']
                person_doc = self.Tables[database]['person_doc']
                topics = self.Tables[database]['topics']
                topic_doc = self.Tables[database]['topic_doc']
                docs = self.Tables[database]['docs']

                person_query = session.query(person_doc.doc_id)\
                                      .filter(person_doc.person_id.in_(p_ids))

                topic_query = session.query(topic_doc.doc_id)\
                                       .filter(topic_doc.topic_id.in_(t_ids))

                if p_logic == 'AND':
                    person_query = person_query.group_by(person_doc.doc_id)\
                                                 .having(func.count('*') == len(set(p_ids)))

                if t_logic == 'AND':
                    topic_query = topic_query.group_by(topic_doc.doc_id)\
                                                 .having(func.count('*') == len(set(t_ids)))

                q = session.query(docs).filter(and_(docs.id.in_(person_query), docs.id.in_(topic_query)))

                q = self.__apply_query_filters(session, q, docs, filters, collection)
                db_results_objects = q.all()    # executes query and returns all documents

                if len(db_results_objects) > 0:
                    count = int(db_results_objects[0][0])
                    total_count = total_count + count

                db_results_flat = self.__package_db_results(db_results_objects, filters)

                self.populate_docs_entities(session, db_results_flat, database, filters)

                for row in db_results_flat:
                    date_val = row['date']
                    if not date_val:
                        date_val = datetime(1200, 1, 1, 0, 0)
                    if isinstance(date_val, date):
                        # convert to datetime object if it's just date
                        date_val = datetime.combine(date_val, datetime.min.time())
                    result_list.append((row, collection, date_val))

        (results_combined, collection_next_index, has_next) = self.__merge_collections_results(result_list, filters['page_size'], filters['page_start_index'].copy())

        # build link
        collapsed_start_index = ":".join([":".join([key, str(value)]) for key, value in filters['page_start_index'].items()])
        collapsed_next_index = ":".join([":".join([key, str(value)]) for key, value in collection_next_index.items()])
        next_page = self.clerk.build_link(filters['page_url'], collapsed_start_index, collapsed_next_index, has_next)

        response = self.clerk.process(results_combined, Controller.HTTP_STATUS_SUCCESS, self.clerk.JSON.encode,
            page=collapsed_start_index, page_size=Controller.PAGE_SIZE_DEFAULT, next_page=next_page,count=total_count)
        response.mimetype = 'application/json'
        response.headers['Content-Type'] = 'application/json'
        session.close()
        return response


    def find_docs_by_country_topic(self, c_ids, c_logic, t_ids, t_logic, filters):
        """
        This function returns the document information given a list
        of country and topic ids.

        @type  c_ids: list
        @param c_ids: A list of country ids to query the database for.
        @type  c_logic: string
        @param c_logic: AND / OR operator
        @type  t_ids: list
        @param t_ids: A list of topic ids to query the databases for.
        @type  t_logic: string
        @param t_logic: AND / OR operator
        @type  filters: dictionary
        @param filters: A list of filters to constrain a query.

        @rtype:   json
        @return:  Array of documents info.
        """
        session = self.Session()
        result_list = []
        total_count = 0

        for collection in filters['collections']:
            database = self.collection_names[collection]

            table_names = self.Tables[database].keys()
            if set(['topics', 'topic_doc', 'countries', 'country_doc', 'docs']) <= set(table_names):
                topics = self.Tables[database]['topics']
                topic_doc = self.Tables[database]['topic_doc']
                countries = self.Tables[database]['countries']
                country_doc = self.Tables[database]['country_doc']
                docs = self.Tables[database]['docs']

                topic_query = session.query(topic_doc.doc_id)\
                                     .filter(topic_doc.topic_id.in_(t_ids))

                country_query = session.query(country_doc.doc_id)\
                                       .filter(country_doc.country_id.in_(c_ids))

                if t_logic == 'AND':
                    topic_query = topic_query.group_by(topic_doc.doc_id)\
                                               .having(func.count('*') == len(set(t_ids)))

                if c_logic == 'AND':
                    country_query = country_query.group_by(country_doc.doc_id)\
                                                 .having(func.count('*') == len(set(c_ids)))

                q = session.query(docs).filter(and_(docs.id.in_(topic_query), docs.id.in_(country_query)))

                q = self.__apply_query_filters(session, q, docs, filters, collection)
                db_results_objects = q.all()    # executes query and returns all documents

                if len(db_results_objects) > 0:
                    count = int(db_results_objects[0][0])
                    total_count = total_count + count

                db_results_flat = self.__package_db_results(db_results_objects, filters)

                self.populate_docs_entities(session, db_results_flat, database, filters)

                for row in db_results_flat:
                    date_val = row['date']
                    if not date_val:
                        date_val = datetime(1200, 1, 1, 0, 0)
                    if isinstance(date_val, date):
                        # convert to datetime object if it's just date
                        date_val = datetime.combine(date_val, datetime.min.time())
                    result_list.append((row, collection, date_val))

        (results_combined, collection_next_index, has_next) = self.__merge_collections_results(result_list, filters['page_size'], filters['page_start_index'].copy())

        # build link
        collapsed_start_index = ":".join([":".join([key, str(value)]) for key, value in filters['page_start_index'].items()])
        collapsed_next_index = ":".join([":".join([key, str(value)]) for key, value in collection_next_index.items()])
        next_page = self.clerk.build_link(filters['page_url'], collapsed_start_index, collapsed_next_index, has_next)

        response = self.clerk.process(results_combined, Controller.HTTP_STATUS_SUCCESS, self.clerk.JSON.encode,
            page=collapsed_start_index, page_size=Controller.PAGE_SIZE_DEFAULT, next_page=next_page,count=total_count)
        response.mimetype = 'application/json'
        response.headers['Content-Type'] = 'application/json'
        session.close()
        return response


    def find_docs_by_person_country_topic(self, p_ids, p_logic, c_ids, c_logic, t_ids, t_logic, filters):
        """
        This function returns the document information given a list
        of person and country and topic ids.

        @type  p_ids: list
        @param p_ids: A list of person ids to query the database for.
        @type  p_logic: string
        @param p_logic: AND / OR operator
        @type  c_ids: list
        @param c_ids: A list of country ids to query the databases for.
        @type  c_logic: string
        @param c_logic: AND / OR operator
        @type  t_ids: list
        @param t_ids: A list of topic ids to query the databases for.
        @type  t_logic: string
        @param t_logic: AND / OR operator
        @type  filters: dictionary
        @param filters: A list of filters to constrain a query.

        @rtype:   json
        @return:  Array of documents info.
        """
        session = self.Session()
        result_list = []
        total_count = 0

        for collection in filters['collections']:
            database = self.collection_names[collection]

            table_names = self.Tables[database].keys()
            if set(['topics', 'topic_doc', 'countries', 'country_doc', 'persons', 'person_doc', 'docs']) <= set(table_names):
                topics = self.Tables[database]['topics']
                topic_doc = self.Tables[database]['topic_doc']
                countries = self.Tables[database]['countries']
                country_doc = self.Tables[database]['country_doc']
                persons = self.Tables[database]['persons']
                person_doc = self.Tables[database]['person_doc']
                docs = self.Tables[database]['docs']

                topic_query = session.query(topic_doc.doc_id)\
                                     .filter(topic_doc.topic_id.in_(t_ids))

                country_query = session.query(country_doc.doc_id)\
                                       .filter(country_doc.country_id.in_(c_ids))

                person_query = session.query(person_doc.doc_id)\
                                       .filter(person_doc.person_id.in_(p_ids))

                if t_logic == 'AND':
                    topic_query = topic_query.group_by(topic_doc.doc_id)\
                                               .having(func.count('*') == len(set(t_ids)))

                if c_logic == 'AND':
                    country_query = country_query.group_by(country_doc.doc_id)\
                                                 .having(func.count('*') == len(set(c_ids)))

                if p_logic == 'AND':
                    person_query = person_query.group_by(person_doc.doc_id)\
                                                 .having(func.count('*') == len(set(p_ids)))

                q = session.query(docs).filter(and_(docs.id.in_(topic_query), docs.id.in_(country_query), docs.id.in_(person_query)))

                q = self.__apply_query_filters(session, q, docs, filters, collection)
                db_results_objects = q.all()    # executes query and returns all documents

                if len(db_results_objects) > 0:
                    count = int(db_results_objects[0][0])
                    total_count = total_count + count

                db_results_flat = self.__package_db_results(db_results_objects, filters)

                self.populate_docs_entities(session, db_results_flat, database, filters)

                for row in db_results_flat:
                    date_val = row['date']
                    if not date_val:
                        date_val = datetime(1200, 1, 1, 0, 0)
                    if isinstance(date_val, date):
                        # convert to datetime object if it's just date
                        date_val = datetime.combine(date_val, datetime.min.time())
                    result_list.append((row, collection, date_val))

        (results_combined, collection_next_index, has_next) = self.__merge_collections_results(result_list, filters['page_size'], filters['page_start_index'].copy())

        # build link
        collapsed_start_index = ":".join([":".join([key, str(value)]) for key, value in filters['page_start_index'].items()])
        collapsed_next_index = ":".join([":".join([key, str(value)]) for key, value in collection_next_index.items()])
        next_page = self.clerk.build_link(filters['page_url'], collapsed_start_index, collapsed_next_index, has_next)

        response = self.clerk.process(results_combined, Controller.HTTP_STATUS_SUCCESS, self.clerk.JSON.encode,
            page=collapsed_start_index, page_size=Controller.PAGE_SIZE_DEFAULT, next_page=next_page,count=total_count)
        response.mimetype = 'application/json'
        response.headers['Content-Type'] = 'application/json'
        session.close()
        return response

    def find_docs_by_person_classification_topic(self, p_ids, p_logic, c_ids, c_logic, t_ids, t_logic, filters):
        """
        This function returns the document information given a list
        of person and classification and topic ids.

        @type  p_ids: list
        @param p_ids: A list of person ids to query the database for.
        @type  p_logic: string
        @param p_logic: AND / OR operator
        @type  c_ids: list
        @param c_ids: A list of classification ids to query the databases for.
        @type  c_logic: string
        @param c_logic: AND / OR operator
        @type  t_ids: list
        @param t_ids: A list of topic ids to query the databases for.
        @type  t_logic: string
        @param t_logic: AND / OR operator
        @type  filters: dictionary
        @param filters: A list of filters to constrain a query.

        @rtype:   json
        @return:  Array of documents info.
        """
        session = self.Session()
        result_list = []
        total_count = 0

        for collection in filters['collections']:
            database = self.collection_names[collection]

            table_names = self.Tables[database].keys()
            if set(['topics', 'topic_doc', 'classifications', 'classification_doc', 'persons', 'person_doc', 'docs']) <= set(table_names):
                topics = self.Tables[database]['topics']
                topic_doc = self.Tables[database]['topic_doc']
                classifications = self.Tables[database]['classifications']
                classification_doc = self.Tables[database]['classification_doc']
                persons = self.Tables[database]['persons']
                person_doc = self.Tables[database]['person_doc']
                docs = self.Tables[database]['docs']

                topic_query = session.query(topic_doc.doc_id)\
                                     .filter(topic_doc.topic_id.in_(t_ids))

                classification_query = session.query(classification_doc.doc_id)\
                                       .filter(classification_doc.classification_id.in_(c_ids))

                person_query = session.query(person_doc.doc_id)\
                                       .filter(person_doc.person_id.in_(p_ids))

                if t_logic == 'AND':
                    topic_query = topic_query.group_by(topic_doc.doc_id)\
                                               .having(func.count('*') == len(set(t_ids)))

                if c_logic == 'AND':
                    classification_query = classification_query.group_by(classification_doc.doc_id)\
                                                 .having(func.count('*') == len(set(c_ids)))

                if p_logic == 'AND':
                    person_query = person_query.group_by(person_doc.doc_id)\
                                                 .having(func.count('*') == len(set(p_ids)))

                q = session.query(docs).filter(and_(docs.id.in_(topic_query), docs.id.in_(classification_query), docs.id.in_(person_query)))

                q = self.__apply_query_filters(session, q, docs, filters, collection)
                db_results_objects = q.all()    # executes query and returns all documents

                if len(db_results_objects) > 0:
                    count = int(db_results_objects[0][0])
                    total_count = total_count + count

                db_results_flat = self.__package_db_results(db_results_objects, filters)

                self.populate_docs_entities(session, db_results_flat, database, filters)

                for row in db_results_flat:
                    date_val = row['date']
                    if not date_val:
                        date_val = datetime(1200, 1, 1, 0, 0)
                    if isinstance(date_val, date):
                        # convert to datetime object if it's just date
                        date_val = datetime.combine(date_val, datetime.min.time())
                    result_list.append((row, collection, date_val))

        (results_combined, collection_next_index, has_next) = self.__merge_collections_results(result_list, filters['page_size'], filters['page_start_index'].copy())

        # build link
        collapsed_start_index = ":".join([":".join([key, str(value)]) for key, value in filters['page_start_index'].items()])
        collapsed_next_index = ":".join([":".join([key, str(value)]) for key, value in collection_next_index.items()])
        next_page = self.clerk.build_link(filters['page_url'], collapsed_start_index, collapsed_next_index, has_next)

        response = self.clerk.process(results_combined, Controller.HTTP_STATUS_SUCCESS, self.clerk.JSON.encode,
            page=collapsed_start_index, page_size=Controller.PAGE_SIZE_DEFAULT, next_page=next_page,count=total_count)
        response.mimetype = 'application/json'
        response.headers['Content-Type'] = 'application/json'
        session.close()
        return response

    def find_docs_by_classification_country_topic(self, p_ids, p_logic, c_ids, c_logic, t_ids, t_logic, filters):
        """
        This function returns the document information given a list
        of classification and country and topic ids.

        @type  p_ids: list
        @param p_ids: A list of classification ids to query the database for.
        @type  p_logic: string
        @param p_logic: AND / OR operator
        @type  c_ids: list
        @param c_ids: A list of country ids to query the databases for.
        @type  c_logic: string
        @param c_logic: AND / OR operator
        @type  t_ids: list
        @param t_ids: A list of topic ids to query the databases for.
        @type  t_logic: string
        @param t_logic: AND / OR operator
        @type  filters: dictionary
        @param filters: A list of filters to constrain a query.

        @rtype:   json
        @return:  Array of documents info.
        """
        session = self.Session()
        result_list = []
        total_count = 0

        for collection in filters['collections']:
            database = self.collection_names[collection]

            table_names = self.Tables[database].keys()
            if set(['topics', 'topic_doc', 'countries', 'country_doc', 'classifications', 'classification_doc', 'docs']) <= set(table_names):
                topics = self.Tables[database]['topics']
                topic_doc = self.Tables[database]['topic_doc']
                countries = self.Tables[database]['countries']
                country_doc = self.Tables[database]['country_doc']
                classifications = self.Tables[database]['classifications']
                classification_doc = self.Tables[database]['classification_doc']
                docs = self.Tables[database]['docs']

                topic_query = session.query(topic_doc.doc_id)\
                                     .filter(topic_doc.topic_id.in_(t_ids))

                country_query = session.query(country_doc.doc_id)\
                                       .filter(country_doc.country_id.in_(c_ids))

                classification_query = session.query(classification_doc.doc_id)\
                                       .filter(classification_doc.classification_id.in_(p_ids))

                if t_logic == 'AND':
                    topic_query = topic_query.group_by(topic_doc.doc_id)\
                                               .having(func.count('*') == len(set(t_ids)))

                if c_logic == 'AND':
                    country_query = country_query.group_by(country_doc.doc_id)\
                                                 .having(func.count('*') == len(set(c_ids)))

                if p_logic == 'AND':
                    classification_query = classification_query.group_by(classification_doc.doc_id)\
                                                 .having(func.count('*') == len(set(p_ids)))

                q = session.query(docs).filter(and_(docs.id.in_(topic_query), docs.id.in_(country_query), docs.id.in_(classification_query)))

                q = self.__apply_query_filters(session, q, docs, filters, collection)
                db_results_objects = q.all()    # executes query and returns all documents

                if len(db_results_objects) > 0:
                    count = int(db_results_objects[0][0])
                    total_count = total_count + count

                db_results_flat = self.__package_db_results(db_results_objects, filters)

                self.populate_docs_entities(session, db_results_flat, database, filters)

                for row in db_results_flat:
                    date_val = row['date']
                    if not date_val:
                        date_val = datetime(1200, 1, 1, 0, 0)
                    if isinstance(date_val, date):
                        # convert to datetime object if it's just date
                        date_val = datetime.combine(date_val, datetime.min.time())
                    result_list.append((row, collection, date_val))

        (results_combined, collection_next_index, has_next) = self.__merge_collections_results(result_list, filters['page_size'], filters['page_start_index'].copy())

        # build link
        collapsed_start_index = ":".join([":".join([key, str(value)]) for key, value in filters['page_start_index'].items()])
        collapsed_next_index = ":".join([":".join([key, str(value)]) for key, value in collection_next_index.items()])
        next_page = self.clerk.build_link(filters['page_url'], collapsed_start_index, collapsed_next_index, has_next)

        response = self.clerk.process(results_combined, Controller.HTTP_STATUS_SUCCESS, self.clerk.JSON.encode,
            page=collapsed_start_index, page_size=Controller.PAGE_SIZE_DEFAULT, next_page=next_page,count=total_count)
        response.mimetype = 'application/json'
        response.headers['Content-Type'] = 'application/json'
        session.close()
        return response

    def find_docs_by_person_country_classification(self, p_ids, p_logic, c_ids, c_logic, t_ids, t_logic, filters):
        """
        This function returns the document information given a list
        of person and country and classification ids.

        @type  p_ids: list
        @param p_ids: A list of person ids to query the database for.
        @type  p_logic: string
        @param p_logic: AND / OR operator
        @type  c_ids: list
        @param c_ids: A list of country ids to query the databases for.
        @type  c_logic: string
        @param c_logic: AND / OR operator
        @type  t_ids: list
        @param t_ids: A list of classification ids to query the databases for.
        @type  t_logic: string
        @param t_logic: AND / OR operator
        @type  filters: dictionary
        @param filters: A list of filters to constrain a query.

        @rtype:   json
        @return:  Array of documents info.
        """
        session = self.Session()
        result_list = []
        total_count = 0

        for collection in filters['collections']:
            database = self.collection_names[collection]

            table_names = self.Tables[database].keys()
            if set(['classifications', 'classification_doc', 'countries', 'country_doc', 'persons', 'person_doc', 'docs']) <= set(table_names):
                classifications = self.Tables[database]['classifications']
                classification_doc = self.Tables[database]['classification_doc']
                countries = self.Tables[database]['countries']
                country_doc = self.Tables[database]['country_doc']
                persons = self.Tables[database]['persons']
                person_doc = self.Tables[database]['person_doc']
                docs = self.Tables[database]['docs']

                classification_query = session.query(classification_doc.doc_id)\
                                     .filter(classification_doc.classification_id.in_(t_ids))

                country_query = session.query(country_doc.doc_id)\
                                       .filter(country_doc.country_id.in_(c_ids))

                person_query = session.query(person_doc.doc_id)\
                                       .filter(person_doc.person_id.in_(p_ids))

                if t_logic == 'AND':
                    classification_query = classification_query.group_by(classification_doc.doc_id)\
                                               .having(func.count('*') == len(set(t_ids)))

                if c_logic == 'AND':
                    country_query = country_query.group_by(country_doc.doc_id)\
                                                 .having(func.count('*') == len(set(c_ids)))

                if p_logic == 'AND':
                    person_query = person_query.group_by(person_doc.doc_id)\
                                                 .having(func.count('*') == len(set(p_ids)))

                q = session.query(docs).filter(and_(docs.id.in_(classification_query), docs.id.in_(country_query), docs.id.in_(person_query)))

                q = self.__apply_query_filters(session, q, docs, filters, collection)
                db_results_objects = q.all()    # executes query and returns all documents

                if len(db_results_objects) > 0:
                    count = int(db_results_objects[0][0])
                    total_count = total_count + count

                db_results_flat = self.__package_db_results(db_results_objects, filters)

                self.populate_docs_entities(session, db_results_flat, database, filters)

                for row in db_results_flat:
                    date_val = row['date']
                    if not date_val:
                        date_val = datetime(1200, 1, 1, 0, 0)
                    if isinstance(date_val, date):
                        # convert to datetime object if it's just date
                        date_val = datetime.combine(date_val, datetime.min.time())
                    result_list.append((row, collection, date_val))

        (results_combined, collection_next_index, has_next) = self.__merge_collections_results(result_list, filters['page_size'], filters['page_start_index'].copy())

        # build link
        collapsed_start_index = ":".join([":".join([key, str(value)]) for key, value in filters['page_start_index'].items()])
        collapsed_next_index = ":".join([":".join([key, str(value)]) for key, value in collection_next_index.items()])
        next_page = self.clerk.build_link(filters['page_url'], collapsed_start_index, collapsed_next_index, has_next)

        response = self.clerk.process(results_combined, Controller.HTTP_STATUS_SUCCESS, self.clerk.JSON.encode,
            page=collapsed_start_index, page_size=Controller.PAGE_SIZE_DEFAULT, next_page=next_page,count=total_count)
        response.mimetype = 'application/json'
        response.headers['Content-Type'] = 'application/json'
        session.close()
        return response

    def find_docs_by_person_country_topic_classification(self, p_ids, p_logic, c_ids, c_logic, t_ids, t_logic, f_ids, f_logic, filters):
        """
        This function returns the document information given a list
        of person and country and topic and classification ids.

        @type  p_ids: list
        @param p_ids: A list of person ids to query the database for.
        @type  p_logic: string
        @param p_logic: AND / OR operator
        @type  c_ids: list
        @param c_ids: A list of country ids to query the databases for.
        @type  c_logic: string
        @param c_logic: AND / OR operator
        @type  t_ids: list
        @param t_ids: A list of topic ids to query the databases for.
        @type  t_logic: string
        @param t_logic: AND / OR operator
        @type  f_ids: list
        @param f_ids: A list of classification ids to query the databases for.
        @type  f_logic: string
        @param f_logic: AND / OR operator
        @type  filters: dictionary
        @param filters: A list of filters to constrain a query.

        @rtype:   json
        @return:  Array of documents info.
        """
        session = self.Session()
        result_list = []
        total_count = 0

        for collection in filters['collections']:
            database = self.collection_names[collection]

            table_names = self.Tables[database].keys()
            if set(['topics', 'topic_doc', 'countries', 'country_doc', 'persons', 'person_doc', 'classifications', 'classification_doc', 'docs']) <= set(table_names):
                topics = self.Tables[database]['topics']
                topic_doc = self.Tables[database]['topic_doc']
                countries = self.Tables[database]['countries']
                country_doc = self.Tables[database]['country_doc']
                persons = self.Tables[database]['persons']
                person_doc = self.Tables[database]['person_doc']
                classifications = self.Tables[database]['classifications']
                classification_doc = self.Tables[database]['classification_doc']
                docs = self.Tables[database]['docs']

                topic_query = session.query(topic_doc.doc_id)\
                                     .filter(topic_doc.topic_id.in_(t_ids))

                country_query = session.query(country_doc.doc_id)\
                                       .filter(country_doc.country_id.in_(c_ids))

                person_query = session.query(person_doc.doc_id)\
                                       .filter(person_doc.person_id.in_(p_ids))

                classification_query = session.query(classification_doc.doc_id)\
                                       .filter(classification_doc.classification_id.in_(f_ids))

                if t_logic == 'AND':
                    topic_query = topic_query.group_by(topic_doc.doc_id)\
                                               .having(func.count('*') == len(set(t_ids)))

                if c_logic == 'AND':
                    country_query = country_query.group_by(country_doc.doc_id)\
                                                 .having(func.count('*') == len(set(c_ids)))

                if p_logic == 'AND':
                    person_query = person_query.group_by(person_doc.doc_id)\
                                                 .having(func.count('*') == len(set(p_ids)))

                if f_logic == 'AND':
                    classification_query = classification_query.group_by(classification_doc.doc_id)\
                                                 .having(func.count('*') == len(set(f_ids)))

                q = session.query(docs).filter(and_(docs.id.in_(topic_query), docs.id.in_(country_query), docs.id.in_(person_query), docs.id.in_(classification_query)))

                q = self.__apply_query_filters(session, q, docs, filters, collection)
                db_results_objects = q.all()    # executes query and returns all documents

                if len(db_results_objects) > 0:
                    count = int(db_results_objects[0][0])
                    total_count = total_count + count

                db_results_flat = self.__package_db_results(db_results_objects, filters)

                self.populate_docs_entities(session, db_results_flat, database, filters)

                for row in db_results_flat:
                    date_val = row['date']
                    if not date_val:
                        date_val = datetime(1200, 1, 1, 0, 0)
                    if isinstance(date_val, date):
                        # convert to datetime object if it's just date
                        date_val = datetime.combine(date_val, datetime.min.time())
                    result_list.append((row, collection, date_val))

        (results_combined, collection_next_index, has_next) = self.__merge_collections_results(result_list, filters['page_size'], filters['page_start_index'].copy())

        # build link
        collapsed_start_index = ":".join([":".join([key, str(value)]) for key, value in filters['page_start_index'].items()])
        collapsed_next_index = ":".join([":".join([key, str(value)]) for key, value in collection_next_index.items()])
        next_page = self.clerk.build_link(filters['page_url'], collapsed_start_index, collapsed_next_index, has_next)

        response = self.clerk.process(results_combined, Controller.HTTP_STATUS_SUCCESS, self.clerk.JSON.encode,
            page=collapsed_start_index, page_size=Controller.PAGE_SIZE_DEFAULT, next_page=next_page,count=total_count)
        response.mimetype = 'application/json'
        response.headers['Content-Type'] = 'application/json'
        session.close()
        return response

    def find_docs_by_date(self, filters):
        """
        This function returns the document information filtered
        by a date range.

        @type  filters: dictionary
        @param filters: A list of filters to constrain a query.

        @rtype:   json
        @return:  Array of documents info.
        """
        session = self.Session()
        result_list = []
        total_count = 0

        for collection in filters['collections']:
            database = self.collection_names[collection]

            table_names = self.Tables[database].keys()
            if 'docs' in table_names:
                docs = self.Tables[database]['docs']

                q = session.query(docs)
                q = self.__apply_query_filters(session, q, docs, filters, collection)

                db_results_objects = q.all()    # returns all documents

                if len(db_results_objects) > 0:
                    count = int(db_results_objects[0][0])
                    total_count = total_count + count

                db_results_flat = self.__package_db_results(db_results_objects, filters)

                self.populate_docs_entities(session, db_results_flat, database, filters)

                for row in db_results_flat:
                    date_val = row['date']
                    if not date_val:
                        date_val = datetime(1200, 1, 1, 0, 0)
                    if isinstance(date_val, date):
                        # convert to datetime object if it's just date
                        date_val = datetime.combine(date_val, datetime.min.time())
                    result_list.append((row, collection, date_val))

        (results_combined, collection_next_index, has_next) = self.__merge_collections_results(result_list, filters['page_size'], filters['page_start_index'].copy())

        # build link
        collapsed_start_index = ":".join([":".join([key, str(value)]) for key, value in filters['page_start_index'].items()])
        collapsed_next_index = ":".join([":".join([key, str(value)]) for key, value in collection_next_index.items()])
        next_page = self.clerk.build_link(filters['page_url'], collapsed_start_index, collapsed_next_index, has_next)

        response = self.clerk.process(results_combined, Controller.HTTP_STATUS_SUCCESS, self.clerk.JSON.encode,
            page=collapsed_start_index, page_size=Controller.PAGE_SIZE_DEFAULT, next_page=next_page,count=total_count)
        response.mimetype = 'application/json'
        response.headers['Content-Type'] = 'application/json'
        session.close()
        return response


    def get_overview_data(self, entity, limit, geo_ids, filters, request_url):
        """
        This function is used by the declass_overview() API route.
        """

        collection = filters['collections'][0]
        start_date = filters['start_date']
        end_date = filters['end_date']

        session = self.Session()
        result_list = []
        database = self.collection_names[collection]
        table_names = self.Tables[database].keys()

        entity_doc = ""
        if entity == "countries":
            entity_doc = "country_doc"
        if entity == "persons":
            entity_doc = "person_doc"
        if entity == "topics":
            entity_doc = "topic_doc"
        if entity == "classifications":
            entity_doc = "classification_doc"

        if entity in table_names and entity_doc in table_names and "docs" in table_names:
            entity = self.Tables[database][entity]
            entity_doc = self.Tables[database][entity_doc]
            docs = self.Tables[database]['docs']

            # Two types of calls: 1. Filter given geo_ids and data range, 2. Filter with dates only
            q = session.query(entity.id, entity.name, func.count('*').label('total_docs'))\
                .join(entity_doc).filter(and_(entity_doc.date >= start_date, entity_doc.date <= end_date))\
                .filter(entity.name != "Null").group_by(entity.id).order_by(desc('total_docs')).limit(limit)

            #if geo_ids:
            #    if "country_doc" in table_names:
            #        country_doc = self.Tables[database]['country_doc']
            #        q = session.query(entity.id, entity.name, func.count('*').label('total_docs'))\
            #            .join(entity_doc).filter(and_(entity_doc.date >= start_date, entity_doc.date <= end_date, country_doc.country_id.in_(geo_ids)))\
            #            .filter(entity.name != "Null").group_by(entity.id).order_by(desc('total_docs')).limit(limit)

            result = q.all()

            for (entity_id, entity_name, doc_count) in result:
                result_list.append({'id':entity_id, 'name':entity_name, 'total_docs':doc_count})

        response = self.clerk.process(result_list, Controller.HTTP_STATUS_SUCCESS, self.clerk.JSON.encode)
        response.mimetype = 'application/json'
        response.headers['Content-Type'] = 'application/json'
        session.close()
        return response


        # Update topics

    def get_collection_topics(self, collection, limit):
        """
        This function is used by the declass_collection_topics() API route.
        """
        result_list = []
        total_count = 0

        # 1st, check if collection name exists
        if(collection not in self.collection_names.keys()):
            return self.clerk.complain(Controller.HTTP_STATUS_BAD_REQUEST, "Invalid API parameters",
                                    [{'KeyError':
                                      'Plese enter a valid collection name'}
                                     ])

        database = self.collection_names[collection]
        table_names = self.Tables[database].keys()

        session = self.Session()
        if 'topic_doc' in table_names and 'topics' in table_names:
            topic_doc = self.Tables[database]['topic_doc']
            topics = self.Tables[database]['topics']

            query = session.query(func.avg(topic_doc.topic_score).label('average_score'),
                                  func.count(topic_doc.topic_id).label('doc_count'),
                                  topic_doc.topic_id.label('topic_id'),
                                  topics.name).join(topics).filter(topics.name != "Null").group_by(topic_doc.topic_id)

            # Subquery for count variable
            query_total_count = query.subquery().count().label('count')
            query_with_limit = query.offset(0).limit(limit).subquery()
            query_combined	= session.query(query_total_count, query_with_limit).all()

            if len(query_combined) > 0:
                    (count, avg_score, doc_count, top_id, title) = query_combined[0]
                    total_count = total_count + count

            for (count, average_score, doc_count, topic_id, title) in query_combined:
                result_list.append({'average_score':average_score, 'doc_count':doc_count, 'topic_id':topic_id, 'title':title})

        response = self.clerk.process({"topics":result_list}, Controller.HTTP_STATUS_SUCCESS, count=total_count)
        response.mimetype = 'application/json'
        response.headers['Content-Type'] = 'application/json'
        session.close()
        return response


    def get_topic_tokens(self, collection, topic_id, limit):
        """
        This function is used by the declass_topic_tokens() API route.
        """

        # 1st, check if collection name exists
        if(collection not in self.collection_names.keys()):
            return self.clerk.complain(Controller.HTTP_STATUS_BAD_REQUEST, "Invalid API parameters",
                                    [{'KeyError':
                                      'Plese enter a valid collection name'}
                                     ])

        database = self.collection_names[collection]
        if 'valid_topic_ids' not in self.Topics[database]:
            return self.clerk.complain(Controller.HTTP_STATUS_BAD_REQUEST, "CollectionError",[{"error": "Collection does not contain topic info"}])

        # Make sure topic_id is valid.
        if topic_id not in self.Topics[database]['valid_topic_ids']:
            return self.clerk.complain(Controller.HTTP_STATUS_BAD_REQUEST, "TopicIdError",[{"error": "Please enter a valid topid_id"}])

        session = self.Session()
        result_count = len(self.Topics[database]['top_topic_tokens'][topic_id])
        tokens = self.Topics[database]['top_topic_tokens'][topic_id][:limit]

        topics = self.Tables[database]['topics']
        topic_name = session.query(topics.name).filter(topics.id == topic_id).filter(topics.name != "Null").first()

        if not topic_name:
        	return self.clerk.complain(Controller.HTTP_STATUS_BAD_REQUEST, "TopicIdError",[{"error": "Please enter a valid topid_id"}])

        result = {
            "topic_title": topic_name[0],
            "topic_id": topic_id,
            "tokens": tokens}

        response = self.clerk.process(result, Controller.HTTP_STATUS_SUCCESS, count=result_count)
        response.mimetype = 'application/json'
        response.headers['Content-Type'] = 'application/json'
        session.close()
        return response


    def get_classification_collection(self, collection):
        """
        This function is used by the declass_classification_count() API route.
        """
        # 1st, check if collection name exists
        if(collection not in self.collection_names.keys()):
            return self.clerk.complain(Controller.HTTP_STATUS_BAD_REQUEST, "Invalid API parameters",
                                    [{'KeyError':
                                      'Plese enter a valid collection name'}
                                     ])

        database = self.collection_names[collection]
        table_names = self.Tables[database].keys()

        enabled_collections = ['ddrs', 'statedeptcables', 'clinton', 'frus']
        if 'docs' in table_names:
            docs = self.Tables[database]['docs']
            q = []
            session = self.Session()
            if collection in enabled_collections:
                if collection == 'statedeptcables':
                    # change column name of cables database to classification
                    q = session.query(docs['class'], func.count(docs['class'])).group_by(docs['class'])
                else:
                    q = session.query(docs.classification, func.count(docs.classification)).group_by(docs.classification)
            else:
                return self.clerk.complain(Controller.HTTP_STATUS_BAD_REQUEST, "Unsupported Collection",[{"error": "Please enter a collection with classifications"}])

            db_results_objects = q.all()
            result = []

            for (classification, count) in db_results_objects:
                result.append({'classification':classification, 'count':count})

            result_count = len(result)
            response = self.clerk.process(result, Controller.HTTP_STATUS_SUCCESS, count=result_count)
            response.mimetype = 'application/json'
            response.headers['Content-Type'] = 'application/json'
            session.close()
            return response
        else:
            return self.clerk.complain(Controller.HTTP_STATUS_BAD_REQUEST, "DocsTableError",[{"error": "Collection does not have a document table"}])



    def get_topic_docs(self, collection, topic_id, limit):
        """
        This function is used by the declass_topic_docs() API route.
        """
        # 1st, check if collection name exists
        if(collection not in self.collection_names.keys()):
            return self.clerk.complain(Controller.HTTP_STATUS_BAD_REQUEST, "Invalid API parameters",
                                    [{'KeyError':
                                      'Plese enter a valid collection name'}
                                     ])

        database = self.collection_names[collection]
        if 'valid_topic_ids' not in self.Topics[database]:
            return self.clerk.complain(Controller.HTTP_STATUS_BAD_REQUEST, "CollectionError",[{"error": "Collection does not contain topic doc"}])

        # Make sure topic_id is valid.
        if topic_id not in self.Topics[database]['valid_topic_ids']:
            return self.clerk.complain(Controller.HTTP_STATUS_BAD_REQUEST, "TopicDocError",[{"error": "Please enter a valid topid_id"}])

        session = self.Session()
        result_count = len(self.Topics[database]['top_topic_docs'][topic_id])
        docs = self.Topics[database]['top_topic_docs'][topic_id][:limit]

        topics = self.Tables[database]['topics']
        topic_name = session.query(topics.name).filter(topics.id == topic_id).filter(topics.name != "Null").first()

        if not topic_name:
        	return self.clerk.complain(Controller.HTTP_STATUS_BAD_REQUEST, "TopicDocError",[{"error": "Please enter a valid topid_id"}])

        # if collection == "cpdoc":
        #     for d in docs:
        #         d['title'] = "Testing"

        result = {
            "topic_title": topic_name[0],
            "topic_id": topic_id,
            "docs": docs}

        response = self.clerk.process(result, Controller.HTTP_STATUS_SUCCESS, count=result_count)
        response.mimetype = 'application/json'
        response.headers['Content-Type'] = 'application/json'
        session.close()
        return response


    def get_doc_topics(self, doc_id):
        """
        This function is used by the declass_doc_topics() API route.
        """
        result_list = []
        session = self.Session()

        docdb = self.Tables['declassification_api']['docdb']

        # Get the database that we need to search document in
        (database,) = session.query(docdb.db_name).filter(docdb.doc_id == doc_id).first()

        if 'valid_topic_ids' not in self.Topics[database]:
            return self.clerk.complain(Controller.HTTP_STATUS_BAD_REQUEST, "CollectionError",[{"error": "Collection does not contain topic doc"}])

        # Make sure doc_id is valid.
        if doc_id not in self.Topics[database]['valid_doc_ids']:
            return self.clerk.complain(Controller.HTTP_STATUS_BAD_REQUEST, "TopicDocError",[{"error": "Please enter a valid topid_id"}])

        topic_doc = self.Tables[database]['topic_doc']
        topics = self.Tables[database]['topics']

        query = session.query(topics.name, topics.id, topic_doc.topic_score)\
                                    .filter(topic_doc.topic_id == topics.id).filter(topic_doc.doc_id == doc_id).all()

        for (title, topic_id, topic_score) in query:
            if title:
                result_list.append({'title':title, 'topic_id':topic_id, 'topic_score':topic_score})

        response = self.clerk.process({"doc_id":doc_id, "topics":result_list}, Controller.HTTP_STATUS_SUCCESS, count=len(result_list))
        response.mimetype = 'application/json'
        response.headers['Content-Type'] = 'application/json'
        session.close()
        return response

    def get_tag_docs(self, collection_name, doc_id):
        """
        This function returns a list of tags for a doc
        """
        if (collection_name != 'statedeptcables'):
            return self.clerk.complain(Controller.HTTP_STATUS_BAD_REQUEST, "Invalid API parameters",
                                    [{'KeyError':
                                      'Plese enter valid collection name for tags'}
                                     ])

        database = 'declassification_cables'
        result_list = {}
        session = self.Session()

        tags = self.Tables[database]['tags']
        tag_doc = self.Tables[database]['tag_doc']

        tags_results = session.query(tags.tag, tags.title).filter(tags.id == tag_doc.tag_id, tag_doc.doc_id == doc_id).all()

        if (len(tags_results) > 0):
            tag_string = ""
            for (tag, tag_title) in tags_results:
                tag_string = tag_string + tag + " (" + tag_title + ")" + ", "
            result_list = {"doc_id": doc_id, "tags": tag_string[:-2]}
        else:
            result_list = {"doc_id": doc_id, "tags": None}

        response = self.clerk.process(result_list, Controller.HTTP_STATUS_SUCCESS, count=len(result_list))
        response.mimetype = 'application/json'
        response.headers['Content-Type'] = 'application/json'
        session.close()
        return response



    def get_config_parameters(self, display=False):
        """
        This function returns a list of the accepted API url parameters.
        """
        if display:
            data = {'parameters': self.api_config['parameters']}
            response_code = Controller.HTTP_STATUS_SUCCESS
            response = self.clerk.process(data, response_code, page=0, page_size=1)
            return response
        return self.api_config['parameters']


    def get_config_fields(self, display=False):
        """
        This function returns a list of the accepted API metadata fields.
        """
        if display:
            data = {'fields': self.api_config['fields']}
            response_code = Controller.HTTP_STATUS_SUCCESS
            response = self.clerk.process(data, response_code, page=0)
            return response
        else:
            return self.api_config['fields']


    def get_collection_names(self, display=False):
        """
        This function returns a list of the supported collection names.
        """
        if display:
            data = {'collections': self.collection_names.keys()}
            response_code = Controller.HTTP_STATUS_SUCCESS
            response = self.clerk.process(data, response_code, page=0)
            return response
        else:
            return self.collection_names.keys()


    def get_entity_info(self, entity, collection, page, page_size, request_url):
        """
        This function is used by the declass_entity_info() API route.
        """
        if page < 0 or page_size < 1:
            return self.clerk.complain(Controller.HTTP_STATUS_BAD_REQUEST, "Invalid API parameters",
                                    [{'KeyError':
                                      'Plese enter valid page and page_size values'}
                                     ])

        # 1st, check if collection name exists
        if(collection not in self.collection_names.keys()):
            return self.clerk.complain(Controller.HTTP_STATUS_BAD_REQUEST, "Invalid API parameters",
                                    [{'KeyError':
                                      'Plese enter a valid collection name'}
                                     ])


        # 2nd, check if an entity has been entered, if not, return all the possible entities of the collection to the user
        database_name = self.collection_names[collection]
        if entity is None:
            data = {'entity': self.Entities[ database_name ] }
            response_code = Controller.HTTP_STATUS_SUCCESS
            response = self.clerk.process(data, response_code, page=0, page_size=1)
            return response

        # 3rd, check that the returned entity is a valid entity for the collection
        if entity not in self.Entities[ database_name ]:
            return self.clerk.complain(Controller.HTTP_STATUS_BAD_REQUEST, "Invalid API parameters",
                                    [{'KeyError':
                                      'The entity you entered is invalid or does not belong to the collection'}
                                     ])


        # 4th, query the database and return results pertaining to the collection and entity
        session = self.Session()
        offset = page * page_size
        query_results = []

        if entity == "persons":
            persons = self.Tables[database_name][entity]
            person_doc =  self.Tables[database_name]['person_doc']

            query_results = session.query(persons.id, persons.name, func.count(persons.id)).join(person_doc).group_by(person_doc.person_id)[  offset : (offset + page_size + 1) ]

        if entity == "countries":
            countries = self.Tables[database_name][entity]
            country_doc =  self.Tables[database_name]['country_doc']

            query_results = session.query(countries.id, countries.name, func.count()).join(country_doc).group_by(country_doc.country_id)[  offset : (offset + page_size + 1) ]

        if entity == "topics":
            topics = self.Tables[database_name][entity]
            topic_doc =  self.Tables[database_name]['topic_doc']

            query_results = session.query(topics.id, topics.title, func.count()).join(topic_doc).group_by(topic_doc.topic_id)[  offset : (offset + page_size + 1) ]


        has_next = False
        if len(query_results) > page_size:
            has_next = True

        results = [{'id': r_id, 'name': r_name, 'count': r_count} for r_id, r_name, r_count in query_results]


        session.close()

        fetched_data = {"results": results[:page_size], "has_next": has_next}

        next_page = self.clerk.build_link(request_url, str(page), str((page+1)), fetched_data['has_next'])

        response = self.clerk.process(fetched_data['results'], Controller.HTTP_STATUS_SUCCESS, self.clerk.JSON.encode,
                                       page=page, page_size=page_size, next_page=next_page)
        response.mimetype = 'application/json'
        response.headers['Content-Type'] = 'application/json'

        return response


    def get_viz_docs(self, table):
        """
        This function is provides access to the visualizations database and returns
        all table rows.

        @type  table: string
        @param table: The name of a table in the visualizations database.

        @rtype:   json
        @return:  Table content.
        """

        doc_type = self.Tables['visualizations'][table]

        session = self.Session()
        query_results = session.query(doc_type).all()

        data = []
        for row in query_results:
            if row:
                fields = row.__table__.columns.keys()
                row_results = dict( (col, getattr(row, col)) for col in fields )
                data.append(row_results)

        session.close()

        response = self.clerk.process(data, Controller.HTTP_STATUS_SUCCESS, self.clerk.JSON.encode, page=0, page_size=len(data))
        response.mimetype = 'application/json'
        response.headers['Content-Type'] = 'application/json'
        return response

    def get_viz_overview(self, databases, tables, limit):
        """
        This function provides access to the visualizations overview and returns
        all table rows.

        @type  table: string
        @param table: The name of a table in the visualizations database.

        @rtype:   json
        @return:  Table content.
        """

        response_data = {}
        for database in databases:
            # HACK: The database name has changed to declassification_cables from
            # declassification_statedeptcables. This preserves backwards
            # compatibility with old code.
            if database == 'statedeptcables':
                database = 'cables'
            response_data[database] = {}
            database_name = "declassification_{0}".format(database)
            for table in tables:

                doc_type = self.Tables[database_name][table]
                session = self.Session()

                if table == "top_persons" or table == "top_countries" or table == "top_topics" or table == "top_classifications":
                    query_results = session.query(doc_type).order_by(desc('doc_count')).limit(limit+20)
                else:
                    query_results = session.query(doc_type).order_by(desc('doc_count'))

                data = []
                for row in query_results:
                    if row:
                        fields = row.__table__.columns.keys()
                        row_results = dict( (col, getattr(row, col)) for col in fields )
                        data.append(row_results)

                if table == 'top_topics':
                    data = [datum for datum in data if datum['title'] is not None]

                if table == "top_persons" or table == "top_countries" or table == "top_topics" or table == "top_classifications":
                    data = data[:limit]

                session.close()

                # HACK to return curect number of topics.
                #if table == 'top_topics':
                #    data = [datum for datum in data if datum['title'] is not None]

                response_data[database][table] = data

        response = self.clerk.process(response_data, Controller.HTTP_STATUS_SUCCESS, self.clerk.JSON.encode, page=0, page_size=len(data))
        response.mimetype = 'application/json'
        response.headers['Content-Type'] = 'application/json'
        return response

    def get_classification_topics(self, collection):
        """
        This function is used by the declass_viz_classification_topics() route
        """
        # 1st, check if collection name exists
        if(collection not in self.collection_names.keys()):
            return self.clerk.complain(Controller.HTTP_STATUS_BAD_REQUEST, "Invalid API parameters",
                                    [{'KeyError':
                                      'Plese enter a valid collection name'}
                                     ])

        database = self.collection_names[collection]
        table_names = self.Tables[database].keys()

        enabled_collections = ['ddrs', 'frus']
        if collection in enabled_collections:
            if 'classification_topics' in table_names:
                c_t = self.Tables[database]['classification_topics']
                q = []
                session = self.Session()
                q = session.query(c_t.topic, c_t.classification, c_t.number, c_t.class_id, c_t.topic_id)
                db_results_objects = q.all()
                result = []

                dict_t = {}
                for (topic, classification, count, class_id, topic_id) in db_results_objects:
                    if topic != None and classification != None:
                        if topic not in dict_t:
                            dict_t[topic] = {}
                            dict_t[topic]['category'] = topic
                            dict_t[topic]['category_id'] = topic_id
                            dict_t[topic]['class_id'] = {}
                        if classification not in dict_t[topic]:
                            dict_t[topic][classification] = count
                            dict_t[topic]['class_id'][classification] = class_id

                for key in dict_t:
                    result.append(dict_t[key])

                result_count = len(result)
                response = self.clerk.process(result, Controller.HTTP_STATUS_SUCCESS, count=result_count)
                response.mimetype = 'application/json'
                response.headers['Content-Type'] = 'application/json'
                session.close()
                return response
            else:
                return self.clerk.complain(Controller.HTTP_STATUS_BAD_REQUEST, "DocsTableError",[{"error": "Collection does not have a document table"}])
        else:
            return self.clerk.complain(Controller.HTTP_STATUS_BAD_REQUEST, "Unsupported Collection",[{"error": "Please enter a collection with classifications"}])


    def get_classification_countries(self, collection):
        """
        This function is used by the declass_viz_classification_countries() route
        """
        # 1st, check if collection name exists
        if(collection not in self.collection_names.keys()):
            return self.clerk.complain(Controller.HTTP_STATUS_BAD_REQUEST, "Invalid API parameters",
                                    [{'KeyError':
                                      'Plese enter a valid collection name'}
                                     ])

        database = self.collection_names[collection]
        table_names = self.Tables[database].keys()

        enabled_collections = ['ddrs', 'frus', 'statedeptcables', 'clinton']
        if collection in enabled_collections:
            if 'classification_countries' in table_names:
                c_t = self.Tables[database]['classification_countries']
                q = []
                session = self.Session()
                q = session.query(c_t.country, c_t.classification, c_t.number, c_t.class_id, c_t.country_id)
                db_results_objects = q.all()
                result = []

                dict_t = {}
                for (country, classification, count, class_id, country_id) in db_results_objects:
                    if country != None and classification != None:
                        if country not in dict_t:
                            dict_t[country] = {}
                            dict_t[country]['category'] = country
                            dict_t[country]['category_id'] = country_id
                            dict_t[country]['class_id'] = {}
                        if classification not in dict_t[country]:
                            dict_t[country][classification] = count
                            dict_t[country]['class_id'][classification] = class_id

                for key in dict_t:
                    result.append(dict_t[key])

                result_count = len(result)
                response = self.clerk.process(result, Controller.HTTP_STATUS_SUCCESS, count=result_count)
                response.mimetype = 'application/json'
                response.headers['Content-Type'] = 'application/json'
                session.close()
                return response
            else:
                return self.clerk.complain(Controller.HTTP_STATUS_BAD_REQUEST, "DocsTableError",[{"error": "Collection does not have a document table"}])
        else:
            return self.clerk.complain(Controller.HTTP_STATUS_BAD_REQUEST, "Unsupported Collection",[{"error": "Please enter a collection with classifications"}])

    def get_classification_persons(self, collection):
        """
        This function is used by the declass_viz_classification_persons() route
        """
        # 1st, check if collection name exists
        if(collection not in self.collection_names.keys()):
            return self.clerk.complain(Controller.HTTP_STATUS_BAD_REQUEST, "Invalid API parameters",
                                    [{'KeyError':
                                      'Plese enter a valid collection name'}
                                     ])

        database = self.collection_names[collection]
        table_names = self.Tables[database].keys()

        enabled_collections = ['frus', 'clinton']
        if collection in enabled_collections:
            if 'classification_persons' in table_names:
                c_t = self.Tables[database]['classification_persons']
                q = []
                session = self.Session()
                q = session.query(c_t.person, c_t.classification, c_t.number, c_t.class_id, c_t.person_id)
                db_results_objects = q.all()
                result = []

                dict_t = {}
                for (person, classification, count, class_id, person_id) in db_results_objects:
                    if person != None and classification != None:
                        if person not in dict_t:
                            dict_t[person] = {}
                            dict_t[person]['category'] = person
                            dict_t[person]['category_id'] = person_id
                            dict_t[person]['class_id'] = {}
                        if classification not in dict_t[person]:
                            dict_t[person][classification] = count
                            dict_t[person]['class_id'][classification] = class_id


                for key in dict_t:
                    result.append(dict_t[key])

                result_count = len(result)
                response = self.clerk.process(result, Controller.HTTP_STATUS_SUCCESS, count=result_count)
                response.mimetype = 'application/json'
                response.headers['Content-Type'] = 'application/json'
                session.close()
                return response
            else:
                return self.clerk.complain(Controller.HTTP_STATUS_BAD_REQUEST, "DocsTableError",[{"error": "Collection does not have a document table"}])
        else:
            return self.clerk.complain(Controller.HTTP_STATUS_BAD_REQUEST, "Unsupported Collection",[{"error": "Please enter a collection with classifications"}])

    def get_random_doc_ids(self, limit):
        """
        This function is used by the random_doc_ids() API route.
        """
        docdb = self.Tables['declassification_api']['docdb']

        session = self.Session()
        query_results = session.query(docdb).order_by(func.rand())[0:limit]

        data = []
        for row in query_results:
            row_results = {"id" : row.doc_id}
            data.append(row_results)


        session.close()

        response = self.clerk.process(data, Controller.HTTP_STATUS_SUCCESS, self.clerk.JSON.encode, page=0, page_size=len(data))
        response.mimetype = 'application/json'
        response.headers['Content-Type'] = 'application/json'
        return response


    def get_merriam_link(self):
        """
        This function returns the Merriam url for the declass user account.
        """
        return self.api_config['merriam_text_drop'][0]


    def get_entity_autocomplete(self, word_start, entity_type):
        """
        This function is used by the declass_entity_autocomplete() API route.
        """

        if entity_type == 'persons':
            entity_table = self.Tables['declassification_api']['persons_autocomplete']
        elif entity_type == 'countries':
            entity_table = self.Tables['declassification_api']['geo_autocomplete']
        elif entity_type == 'topics':
            entity_table = self.Tables['declassification_api']['topics_autocomplete']
        elif entity_type == 'classifications':
            entity_table = self.Tables['declassification_api']['classifications_autocomplete']
        elif entity_type is None:
            entity_table = self.Tables['declassification_api']['all_entities_autocomplete'] # note that classifications are not in all_entities autocomplete
        else:
            return self.clerk.complain(Controller.HTTP_STATUS_BAD_REQUEST, "Invalid API parameters",
                                    [{'KeyError': 'entity %s is not valid;' % entity_type}])


        session = self.Session()
        # the maximum number of letters supported is 6
        word_start = word_start[0:6]
        query_results = session.query(entity_table).filter(entity_table.query == word_start).first()

        data = None
        if not query_results:
            data = json.dumps({"query": word_start , "response": []})
        else:
            data = query_results.response


        session.close()

        response = self.clerk.make_response(data, Controller.HTTP_STATUS_SUCCESS)
        response.mimetype = 'application/json'
        response.headers['Content-Type'] = 'application/json'

        return response


    def full_text_search(self, search_text, filters):
        """
        This function is used by the declass_full_text_search() API route.
        """
        result = []

        start_date = filters['start_date']
        end_date = filters['end_date']
        page = int(filters['page'])
        page_size = int(filters['page_size'])
        page_url = filters['page_url']
        collections = filters['collections']

        collections_text = " OR ".join(collections)
        # search_text = self.clerk.escapeString(search_text)
        full_text_query = 'date:["' + start_date + '" TO "' + end_date + '"] AND ' + search_text + ' AND collection:(' + collections_text + ')'
        matches = self.es.search(index='declass', fields='subject,title,id,collection,date', q=full_text_query, size=(page_size+1), from_=((page-1)*page_size))

        #matches = self.es.search(index='declass', fields='subject,title,id,collection,date', q=search_text)
        #matches = self.es.search(index='declass', fields='subject,title,id,collection,date', q=search_text, size=page_size, from_=((page-1)*page_size))
        hits = matches['hits']['hits']
        total_count = matches['hits']['total']

        has_next = False
        if hits:
            if len(hits) > page_size:
                has_next = True

            for hit in hits:
                h_score = hit['_score']
                h_id = hit['_id']
                h_title = hit['fields']['title'][0]
                h_subject = hit['fields']['subject'][0]
                h_collection = hit['fields']['collection'][0]
                h_date = hit['fields']['date'][0]

                result.append({'id':h_id, 'title':h_title, 'subject':h_subject, 'collection':h_collection, 'date':h_date})

        next_page = self.clerk.build_link(page_url, str(page), str((page+1)), has_next)

        response = self.clerk.process(result, Controller.HTTP_STATUS_SUCCESS, self.clerk.JSON.encode,
            page=page, page_size=page_size, next_page=next_page,count=total_count)


        response.mimetype = 'application/json'
        response.headers['Content-Type'] = 'application/json'
        return response


    def text_drop_search(self, url, text, limit):
        """
        This function is used by the declass_text_drop() API route.
        """
        params = {
            'limit': limit,
            'text': text
        }

        headers = {'content-type': 'application/json'}
        resp = requests.post(url, data=json.dumps(params), headers=headers)

        if resp.status_code != 200:
            return self.clerk.complain(Controller.HTTP_STATUS_BAD_REQUEST, "API Error",
                                    [{'TextDropError':
                                      'There was an error in processing your request'}
                                     ])
        data = json.loads(resp.text)

        doc_ids = []
        for result in data['results']:
            doc_ids.append(result['doc_id'])

        filters = {}
        filters['start_date'] = None
        filters['end_date'] =  None
        filters['exact_date'] = None
        filters['page_size'] = limit
        filters['fields'] = ['collection', 'date', 'title', 'subject', 'id']
        return self.find_docs_by_ids(doc_ids, filters)


    def __apply_query_filters(self, session, query, table, filters, collection):
        """
        Private function to apply user defined constraints to query call.

        @type  session: object
        @param session: A session factory object configured to access all databases.
        @type  query: object
        @param query: A SQLAlchemy-ORM object query to invoke a database
        @type  table: object
        @param table: A database docs table object containing SQLAlchemy mapping to database.
        @type  filters: dictionary
        @param filters: A list of filters to constrain a query.
        @type  collection: string
        @param collection: The name of the database to query

        @rtype:   object
        @return:  A session query combined of two subqueries. The first subquery
            performs a total count operation, while the other fetches data.
        """
        # List of user defined query filters
        start_date = filters['start_date']
        end_date =     filters['end_date']
        exact_date = filters['exact_date']
        fields = filters['fields']
        fields.append('date') # We must have the date and collection attached for sorting documents
        fields.append('collection')
        page_size = filters['page_size']
        row_record = 0
        if collection:
        	row_record = filters['page_start_index'][collection]

        if start_date and end_date:
            query = query.filter(and_(table.date >= start_date, table.date <= end_date))

        if exact_date:
            today_date = datetime.strptime(exact_date, '%Y-%m-%d')
            tomorrow_date = today_date + timedelta(days=1)
            query = query.filter(and_(table.date >= today_date, table.date < tomorrow_date))

        # Refining the columns that we are searching for
        available_table_columns = set(table.__table__.columns.keys())    # Get fields from docs table
        original_filter = fields
        fields = set.intersection(available_table_columns, original_filter)

        # Subquery for count variable
        query_total_count = query.options( load_only('id') ).subquery().count().label('count')

        if fields:
            query = query.options( load_only( *fields ) )

        query_with_limit = query.order_by(asc(table.date))\
                                .offset(row_record).limit(page_size +1).subquery()

        query_combined = session.query(query_total_count, query_with_limit)

        return query_combined


    def __package_db_results(self, results, filters):
        """
        Private function to set unavailable field requests in a particular collection
        to None. The function currently also disables the body text of ddrs collections
        from appearing to an end-user.
        """
        db_results_flat = []

        for row in results:
            row_results = {}
            for col in filters['fields']:
                if hasattr(row, col):
                    row_results[col] = getattr(row, col)
                else:
                    row_results[col] = None
                if col == "readability" and row_results[col]:
                    row_results[col] = str(row_results[col]*100)

            row_results.update({'id':row.id})

            # Hide body text for DDRS collections
            if row_results['collection'] == "ddrs":
                if "body" in row_results:
                    row_results['body'] = None

            db_results_flat.append(row_results)

        return db_results_flat


    def __merge_collections_results(self, unsorted_list, page_size, page_start_index):
        """
        Private function responsible for combining the document results from
        various collections and sorting them by date.
        """
        # Sort list
        result_list = sorted(unsorted_list, key=operator.itemgetter(2))

        cutoff = page_size
        results_combined = []
        collection_last_index = page_start_index
        has_next = False
        for (row, collection, date) in result_list:
            results_combined.append(row)
            collection_last_index[collection] = collection_last_index[collection] + 1
            cutoff = cutoff - 1
            if cutoff == 0:
                if len(results_combined) < len(result_list):
                    has_next = True
                break
        return (results_combined, collection_last_index, has_next)
